{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RJWwR9gamDPM"
      },
      "outputs": [],
      "source": [
        "#| default_exp training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RGDkKs85mDPM"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from torch import tensor,nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3OdZ10osmDPN"
      },
      "outputs": [],
      "source": [
        "from fastcore.test import test_close\n",
        "\n",
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
        "torch.manual_seed(1)\n",
        "mpl.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "path_data = Path('data')\n",
        "path_gz = path_data/'mnist.pkl.gz'\n",
        "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEIyQnLsmDPN"
      },
      "source": [
        "## Initial setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY5Ra3O7mDPN"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7YR7UWYomDPN"
      },
      "outputs": [],
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EvaOJVYjmDPN"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NfVH9HG7mDPN",
        "outputId": "95720c55-716f-4072-ca31-7f195e577fbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model = Model(m, nh, 10)\n",
        "pred = model(x_train)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnZO6g1HmDPO"
      },
      "source": [
        "### Cross entropy loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXo-TqzvmDPO"
      },
      "source": [
        "First, we will need to compute the softmax of our activations. This is defined by:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
        "\n",
        "or more concisely:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum\\limits_{0 \\leq j \\lt n} e^{x_{j}}}$$\n",
        "\n",
        "In practice, we will need the log of the softmax when we calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "weVeNbspmDPO"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yJUoIP8rmDPO",
        "outputId": "cc788cde-04fe-4482-a782-6f742da28b68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.13, -2.29, -2.27,  ..., -2.18, -2.38, -2.36],\n",
              "        [-2.11, -2.37, -2.36,  ..., -2.10, -2.38, -2.29],\n",
              "        [-2.31, -2.37, -2.24,  ..., -2.08, -2.35, -2.32],\n",
              "        ...,\n",
              "        [-2.14, -2.52, -2.24,  ..., -2.21, -2.40, -2.36],\n",
              "        [-2.23, -2.33, -2.35,  ..., -2.19, -2.26, -2.33],\n",
              "        [-2.19, -2.39, -2.26,  ..., -2.21, -2.38, -2.33]], grad_fn=<LogBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "log_softmax(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "999R0PL8mDPO"
      },
      "source": [
        "Note that the formula\n",
        "\n",
        "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$\n",
        "\n",
        "gives a simplification when we compute the log softmax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dyvoMzROmDPO"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEPSRPK-mDPO"
      },
      "source": [
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the [LogSumExp trick](https://en.wikipedia.org/wiki/LogSumExp). The idea is to use the following formula:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "\n",
        "where a is the maximum of the $x_{j}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "U_lF38gdmDPO"
      },
      "outputs": [],
      "source": [
        "def logsumexp(x):\n",
        "    m = x.max(-1)[0]\n",
        "    return m + (x-m[:,None]).exp().sum(-1).log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q-s_EA1mDPO"
      },
      "source": [
        "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UhhAQGugmDPO"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FdPPLcZ0mDPO",
        "outputId": "bfe4ff2e-d8f3-4430-9b72-ecc3e6bc8e1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.13, -2.29, -2.27,  ..., -2.18, -2.38, -2.36],\n",
              "        [-2.11, -2.37, -2.36,  ..., -2.10, -2.38, -2.29],\n",
              "        [-2.31, -2.37, -2.24,  ..., -2.08, -2.35, -2.32],\n",
              "        ...,\n",
              "        [-2.14, -2.52, -2.24,  ..., -2.21, -2.40, -2.36],\n",
              "        [-2.23, -2.33, -2.35,  ..., -2.19, -2.26, -2.33],\n",
              "        [-2.19, -2.39, -2.26,  ..., -2.21, -2.38, -2.33]], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test_close(logsumexp(pred), pred.logsumexp(-1))\n",
        "sm_pred = log_softmax(pred)\n",
        "sm_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7xt2t4TmDPP"
      },
      "source": [
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "\n",
        "But since our $x$s are 1-hot encoded (actually, they're just the integer indices), this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target.\n",
        "\n",
        "This can be done using numpy-style [integer array indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#integer-array-indexing). Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "j4IICiQ4mDPP",
        "outputId": "32f85717-e295-464b-e8ec-b20ee8732ca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y_train[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hyxtJ7CEmDPP",
        "outputId": "7be52ac4-205a-42cf-95ee-6d48a662bdd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-2.25, grad_fn=<SelectBackward0>),\n",
              " tensor(-2.11, grad_fn=<SelectBackward0>),\n",
              " tensor(-2.45, grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "sm_pred[0,5],sm_pred[1,0],sm_pred[2,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SFmnOyXSmDPP",
        "outputId": "81920602-cf1c-403d-971e-9f22435c62ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.25, -2.11, -2.45], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "sm_pred[[0,1,2], y_train[:3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KzC5nmgWmDPP"
      },
      "outputs": [],
      "source": [
        "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ABd5O990mDPP",
        "outputId": "12f8ade4-a6f6-40ea-cce4-5c5557b27351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.30, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "loss = nll(sm_pred, y_train)\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmmANPnQmDPP"
      },
      "source": [
        "Then use PyTorch's implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dXciQWNOmDPP"
      },
      "outputs": [],
      "source": [
        "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmt80AE-mDPP"
      },
      "source": [
        "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yd7TN5APmDPP"
      },
      "outputs": [],
      "source": [
        "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0t8AODkmDPP"
      },
      "source": [
        "## Basic training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIz1td-FmDPP"
      },
      "source": [
        "Basically the training loop repeats over the following steps:\n",
        "- get the output of the model on a batch of inputs\n",
        "- compare the output to the labels we have and compute a loss\n",
        "- calculate the gradients of the loss with respect to every parameter of the model\n",
        "- update said parameters with those gradients to make them a little bit better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Tgtn9balmDPP"
      },
      "outputs": [],
      "source": [
        "loss_func = F.cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XyCWGKzNmDPQ",
        "outputId": "c4893bde-64be-41b9-83c4-830959bd5b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.20,  0.04,  0.06, -0.06, -0.05,  0.08, -0.10,  0.15, -0.05, -0.03], grad_fn=<SelectBackward0>),\n",
              " torch.Size([50, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bs=50                  # batch size\n",
        "\n",
        "xb = x_train[0:bs]     # a mini-batch from x\n",
        "preds = model(xb)      # predictions\n",
        "preds[0], preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RVXgQ3pAmDPQ",
        "outputId": "cb64016d-ae36-4a0e-9cb8-bcfbe5355bca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
              "        3, 9, 8, 5, 9, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "yb = y_train[0:bs]\n",
        "yb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bPfdntK3mDPQ",
        "outputId": "7aef6cbe-997c-4c6c-ac2f-68435b9db44a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.31, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "loss_func(preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bHQ_TRMUmDPQ",
        "outputId": "e65919ad-9181-4955-8622-3c8b721ec1ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 7, 7, 7, 5, 7, 0, 7, 5, 7, 0, 7, 7, 5, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 0, 7, 5, 7, 5, 7, 7, 7, 5, 7, 7, 7, 0, 7, 0, 5, 5, 0, 5, 5,\n",
              "        0, 5, 0, 5, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "preds.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LgxLxWPTmDPQ"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "def accuracy(out, yb): return (out.argmax(dim=1)==yb).float().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6FDJ4pl2mDPQ",
        "outputId": "83cc213b-b533-40ba-9c77-2c6b7a6bc9b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.06)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "accuracy(preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "M7klK4aSmDPQ"
      },
      "outputs": [],
      "source": [
        "lr = 0.5   # learning rate\n",
        "epochs = 3 # how many epochs to train for"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rJUdzX9vmDPQ"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "def report(loss, preds, yb): print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "j2tw30ZQmDPQ",
        "outputId": "204207d4-cd94-4a87-a910-5f2e36dac126",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.31, 0.06\n"
          ]
        }
      ],
      "source": [
        "xb,yb = x_train[:bs],y_train[:bs]\n",
        "preds = model(xb)\n",
        "report(loss_func(preds, yb), preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "VqKCdMSzmDPQ",
        "outputId": "a02920e5-94cf-4431-cfe4-fdbeae2750b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13, 0.96\n",
            "0.08, 0.98\n",
            "0.09, 0.98\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "        s = slice(i, min(n,i+bs))\n",
        "        xb,yb = x_train[s],y_train[s]\n",
        "        preds = model(xb)\n",
        "        loss = loss_func(preds, yb)\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for l in model.layers:\n",
        "                if hasattr(l, 'weight'):\n",
        "                    l.weight -= l.weight.grad * lr\n",
        "                    l.bias   -= l.bias.grad   * lr\n",
        "                    l.weight.grad.zero_()\n",
        "                    l.bias  .grad.zero_()\n",
        "    report(loss, preds, yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbQ5XoxlmDPQ"
      },
      "source": [
        "## Using parameters and optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhDIVmEBmDPQ"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "sHhmzrAumDPR",
        "outputId": "5fad44e1-6fa6-4ceb-f366-9bf069795575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Module(\n",
              "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "m1 = nn.Module()\n",
        "m1.foo = nn.Linear(3,4)\n",
        "m1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ViSYarV7mDPR",
        "outputId": "daaaeca3-af5c-4cc4-b025-3df8433f691d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "list(m1.named_children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rLiTbTyjmDPR",
        "outputId": "145aa461-7c20-4ccc-f188-5939ddc1c543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.named_children at 0x7b9373b0a420>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "m1.named_children()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iDRmww05mDPR",
        "outputId": "1c938d03-55e1-4a5f-d173-1506425edb93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.15,  0.15, -0.24],\n",
              "         [ 0.16, -0.04,  0.30],\n",
              "         [-0.05,  0.50, -0.26],\n",
              "         [-0.40, -0.52,  0.38]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.35,  0.43, -0.28,  0.16], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "list(m1.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "asL5-XpbmDPR"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x): return self.l2(self.relu(self.l1(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "FSBs3K4SmDPR",
        "outputId": "efab7b2f-9257-4a9b-b513-787328b6c866",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "model = MLP(m, nh, 10)\n",
        "model.l1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sWxxYCoGmDPR",
        "outputId": "171cc415-094e-41c1-b6e2-ca290447f226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "yDK_om91mDPR",
        "outputId": "7dfa4607-2b38-42ed-bf9c-3dad9c7a6f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n",
            "relu: ReLU()\n"
          ]
        }
      ],
      "source": [
        "for name,l in model.named_children(): print(f\"{name}: {l}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "w9mwMPRYmDPR",
        "outputId": "a9c6ac63-b47b-4089-8545-05d86788250e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "for p in model.parameters(): print(p.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "LahEvRTEmDPR"
      },
      "outputs": [],
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, n, bs):\n",
        "            s = slice(i, min(n,i+bs))\n",
        "            xb,yb = x_train[s],y_train[s]\n",
        "            preds = model(xb)\n",
        "            loss = loss_func(preds, yb)\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters(): p -= p.grad * lr\n",
        "                model.zero_grad()\n",
        "        report(loss, preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Uj8kLK1GmDPR",
        "outputId": "9600e9ea-36ef-4aea-eb89-cf54a5e36f62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09, 0.96\n",
            "0.06, 0.98\n",
            "0.06, 1.00\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be6Epf17mDPR"
      },
      "source": [
        "Behind the scenes, PyTorch overrides the `__setattr__` function in `nn.Module` so that the submodules you define are properly registered as parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "3Kuv2wrxmDPR"
      },
      "outputs": [],
      "source": [
        "class MyModule:\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        self._modules = {}\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "\n",
        "    def __setattr__(self,k,v):\n",
        "        if not k.startswith(\"_\"): self._modules[k] = v\n",
        "        super().__setattr__(k,v)\n",
        "\n",
        "    def __repr__(self): return f'{self._modules}'\n",
        "\n",
        "    def parameters(self):\n",
        "        for l in self._modules.values(): yield from l.parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "4-SSEH9ImDPR",
        "outputId": "ec60c894-e712-44b7-a8d2-0dcb4639c006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "mdl = MyModule(m,nh,10)\n",
        "mdl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "V6qkangrmDPR",
        "outputId": "67a82f25-2384-43db-eb97-4627c07b4ba7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "for p in mdl.parameters(): print(p.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C-SwrzcmDPR"
      },
      "source": [
        "### Registering modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "hra6QuXBmDPR"
      },
      "outputs": [],
      "source": [
        "from functools import reduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLiIZIY3mDPR"
      },
      "source": [
        "We can use the original `layers` approach, but we have to register the modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "DCDD1iRamDPS"
      },
      "outputs": [],
      "source": [
        "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "fAfrofb0mDPS"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
        "\n",
        "    def forward(self, x): return reduce(lambda val,layer: layer(val), self.layers, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "rPm3wXOlmDPS",
        "outputId": "44c3cf23-6a5c-4ea0-8439-e6f4b04ddcfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "model = Model(layers)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "9W5v4ll7mDPS",
        "outputId": "09b57e64-a2f6-4591-b7c4-2c8da30648b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "model(xb).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjimfLx6mDPS"
      },
      "source": [
        "### nn.ModuleList"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n04MeGnpmDPS"
      },
      "source": [
        "`nn.ModuleList` does this for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "2df80tRwmDPS"
      },
      "outputs": [],
      "source": [
        "class SequentialModel(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "wyy7OSqRmDPS",
        "outputId": "fd790a44-fca2-4553-91c1-5027499061d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "model = SequentialModel(layers)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "htNpgWsZmDPS",
        "outputId": "d5fa902e-872b-453a-e089-50c1227164b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15, 0.96\n",
            "0.11, 0.96\n",
            "0.09, 0.94\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9OFO5LJmDPS"
      },
      "source": [
        "### nn.Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSo1ot_8mDPS"
      },
      "source": [
        "`nn.Sequential` is a convenient class which does the same as the above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "SikjmQmHmDPS"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "cszYsxarmDPS",
        "outputId": "a147ffa1-a2bc-4f94-ea4b-71fdad66f381",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18, 0.94\n",
            "0.13, 0.96\n",
            "0.11, 0.94\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.03, grad_fn=<NllLossBackward0>), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "RwTfoaRkmDPS",
        "outputId": "58d0c6e6-8977-41da-9b96-1a3f553d974d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoeJQ_NumDPS"
      },
      "source": [
        "### optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "4vkhgAsSmDPS"
      },
      "outputs": [],
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
        "\n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            for p in self.params: p -= p.grad * self.lr\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for p in self.params: p.grad.data.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "YNsTXBaqmDPS"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "sGisq7InmDPT"
      },
      "outputs": [],
      "source": [
        "opt = Optimizer(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "5SUIFYA7mDPT",
        "outputId": "1264a893-ded2-4db2-b366-c3a7d600cea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12, 0.98\n",
            "0.09, 0.98\n",
            "0.07, 0.98\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "        s = slice(i, min(n,i+bs))\n",
        "        xb,yb = x_train[s],y_train[s]\n",
        "        preds = model(xb)\n",
        "        loss = loss_func(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    report(loss, preds, yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwecd4xnmDPT"
      },
      "source": [
        "PyTorch already provides this exact functionality in `optim.SGD` (it also handles stuff like momentum, which we'll look at later)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "_b5mZIo5mDPT"
      },
      "outputs": [],
      "source": [
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "OhEN8V28mDPT"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "eonezzkEmDPT",
        "outputId": "6a919bc4-9247-4e66-8fd4-469d1137b93f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.31, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "model,opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Z6PswD02mDPT",
        "outputId": "23d79cda-ea1d-44dd-abba-f7a5df19e4f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.17, 0.96\n",
            "0.11, 0.94\n",
            "0.09, 0.96\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "        s = slice(i, min(n,i+bs))\n",
        "        xb,yb = x_train[s],y_train[s]\n",
        "        preds = model(xb)\n",
        "        loss = loss_func(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    report(loss, preds, yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRIxy9nSmDPT"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk1MBT5tmDPT"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi9BSRWEmDPT"
      },
      "source": [
        "It's clunky to iterate through minibatches of x and y values separately:\n",
        "\n",
        "```python\n",
        "    xb = x_train[s]\n",
        "    yb = y_train[s]\n",
        "```\n",
        "\n",
        "Instead, let's do these two steps together, by introducing a `Dataset` class:\n",
        "\n",
        "```python\n",
        "    xb,yb = train_ds[s]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "anXDjUsrmDPT"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "class Dataset():\n",
        "    def __init__(self, x, y): self.x,self.y = x,y\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i): return self.x[i],self.y[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "EdK6k3z1mDPT"
      },
      "outputs": [],
      "source": [
        "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
        "assert len(train_ds)==len(x_train)\n",
        "assert len(valid_ds)==len(x_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "yCyydsmomDPT",
        "outputId": "d2bbc653-3c5b-4e56-d179-f7fe5d1ec296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "xb,yb = train_ds[0:5]\n",
        "assert xb.shape==(5,28*28)\n",
        "assert yb.shape==(5,)\n",
        "xb,yb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "12Tneq4dmDPT"
      },
      "outputs": [],
      "source": [
        "model,opt = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "H8pNR0xxmDPT",
        "outputId": "8ae9259a-3dc0-45e0-8c47-f3532c151edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11, 0.98\n",
            "0.09, 0.98\n",
            "0.06, 1.00\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "        xb,yb = train_ds[i:min(n,i+bs)]\n",
        "        preds = model(xb)\n",
        "        loss = loss_func(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    report(loss, preds, yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wax-qjs6mDPT"
      },
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ortPKVblmDPT"
      },
      "source": [
        "Previously, our loop iterated over batches (xb, yb) like this:\n",
        "\n",
        "```python\n",
        "for i in range(0, n, bs):\n",
        "    xb,yb = train_ds[i:min(n,i+bs)]\n",
        "    ...\n",
        "```\n",
        "\n",
        "Let's make our loop much cleaner, using a data loader:\n",
        "\n",
        "```python\n",
        "for xb,yb in train_dl:\n",
        "    ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "58wxlITWmDPT"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, ds, bs): self.ds,self.bs = ds,bs\n",
        "    def __iter__(self):\n",
        "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "7ozDcYJEmDPT"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "kooXmPYWmDPT",
        "outputId": "762891b8-9dde-435b-d785-a228d9d36da3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "xb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "vsF-RxFBmDPU",
        "outputId": "9e098342-c976-491a-f747-3e4f69aa599a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 8, 6, 9, 6, 4, 5, 3, 8, 4, 5, 2, 3, 8, 4, 8, 1, 5, 0, 5, 9, 7, 4, 1, 0, 3, 0, 6, 2, 9, 9, 4, 1, 3, 6, 8, 0, 7, 7, 6, 8, 9, 0, 3,\n",
              "        8, 3, 7, 7, 8, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "yb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "oZhTmrGemDPU",
        "outputId": "1669b77c-a980-4436-a347-3128b35420fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "_zf2BSjjmDPU"
      },
      "outputs": [],
      "source": [
        "model,opt = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "BFDg3rermDPU"
      },
      "outputs": [],
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for xb,yb in train_dl:\n",
        "            preds = model(xb)\n",
        "            loss = loss_func(preds, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        report(loss, preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "p6S0rTASmDPU",
        "outputId": "0521aad8-abc1-483f-d223-98b21b48b9fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11, 0.98\n",
            "0.07, 1.00\n",
            "0.08, 0.98\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.04, grad_fn=<NllLossBackward0>), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo7COGKRmDPU"
      },
      "source": [
        "### Random sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoQKbGbcmDPU"
      },
      "source": [
        "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "9cRTgZasmDPU"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "BdZrAiffmDPU"
      },
      "outputs": [],
      "source": [
        "class Sampler():\n",
        "    def __init__(self, ds, shuffle=False): self.n,self.shuffle = len(ds),shuffle\n",
        "    def __iter__(self):\n",
        "        res = list(range(self.n))\n",
        "        if self.shuffle: random.shuffle(res)\n",
        "        return iter(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Z_6MgnCvmDPU"
      },
      "outputs": [],
      "source": [
        "\n",
        "from itertools import islice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "EpZdXq7XmDPU"
      },
      "outputs": [],
      "source": [
        "ss = Sampler(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "3TDCQE_gmDPU",
        "outputId": "10b7c85e-5b3f-4433-b845-06844d8011a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17982\n",
            "23245\n",
            "34240\n",
            "6020\n",
            "41945\n"
          ]
        }
      ],
      "source": [
        "it = iter(ss)\n",
        "for o in range(5): print(next(it))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "A0XXoRdfmDPU",
        "outputId": "a689c883-04bc-4515-933d-2bb130ef5df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31873, 27940, 40553, 3332, 12479]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "list(islice(ss, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "ch8bkbhYmDPU",
        "outputId": "ef64d062-67c3-4721-8444-ce33d32ad6d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[32812, 47556, 36973, 33110, 10626]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "ss = Sampler(train_ds, shuffle=True)\n",
        "list(islice(ss, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "qkfEZ79FmDPU"
      },
      "outputs": [],
      "source": [
        "import fastcore.all as fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "ChJAS9O7mDPU"
      },
      "outputs": [],
      "source": [
        "class BatchSampler():\n",
        "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
        "    def __iter__(self): yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "y7ISR093mDPU",
        "outputId": "cb4a2d16-b22a-4f5a-adf4-c77730a8afb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[24947, 4552, 27929, 19006],\n",
              " [17155, 41735, 15185, 18674],\n",
              " [39972, 31218, 11681, 6567],\n",
              " [15061, 20958, 23984, 49635],\n",
              " [39363, 28941, 15660, 42280]]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "batchs = BatchSampler(ss, 4)\n",
        "list(islice(batchs, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "FRJSKLgfmDPU"
      },
      "outputs": [],
      "source": [
        "def collate(b):\n",
        "    xs,ys = zip(*b)\n",
        "    return torch.stack(xs),torch.stack(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "BvJYHiGUmDPU"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
        "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "8uR2XAnJmDPU"
      },
      "outputs": [],
      "source": [
        "train_samp = BatchSampler(Sampler(train_ds, shuffle=True ), bs)\n",
        "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "ly1xmFP0mDPV"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
        "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "gThPK10JmDPV",
        "outputId": "50e99a2c-6044-4322-87c9-1cd13245ee89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkDmycQamDPV",
        "outputId": "9aed0b6e-d387-40c8-ba1d-4efb7019c0aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([50, 784]), torch.Size([50]))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xb.shape,yb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiUb4-OCmDPV"
      },
      "outputs": [],
      "source": [
        "model,opt = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltDQsRl7mDPV",
        "outputId": "fa050ac3-80cb-495e-edb0-295a2059f6f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.27, 0.04\n",
            "0.15, 0.02\n",
            "0.01, 0.12\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PftxwgjmmDPV"
      },
      "source": [
        "### Multiprocessing DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVja6QgkmDPV"
      },
      "outputs": [],
      "source": [
        "import torch.multiprocessing as mp\n",
        "from fastcore.basics import store_attr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGvzuGcpmDPV",
        "outputId": "aa32be5a-0c5d-492f-d55e-bd9356a1230a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([1, 1, 1, 0]))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds[[3,6,8,1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoqK34wVmDPV",
        "outputId": "dc9fef34-84be-4af7-9cb3-0375ce394342"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([1, 1, 1, 0]))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds.__getitem__([3,6,8,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhULa0UfmDPV",
        "outputId": "100368dd-5e29-4fc5-91f0-a8fd5826a4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
            "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
          ]
        }
      ],
      "source": [
        "for o in map(train_ds.__getitem__, ([3,6],[8,1])): print(o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o5wEjsImDPV"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, ds, batchs, n_workers=1, collate_fn=collate): fc.store_attr()\n",
        "    def __iter__(self):\n",
        "        with mp.Pool(self.n_workers) as ex: yield from ex.map(self.ds.__getitem__, iter(self.batchs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4a_fKHrmDPV"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, batchs=train_samp, n_workers=2)\n",
        "it = iter(train_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBu9QPbfmDPV"
      },
      "outputs": [],
      "source": [
        "xb,yb = next(it)\n",
        "xb.shape,yb.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUTpmmJXmDPV"
      },
      "source": [
        "### PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqwyD8NSmDPV"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AoJLu-UmDPV"
      },
      "outputs": [],
      "source": [
        "train_samp = BatchSampler(RandomSampler(train_ds),     bs, drop_last=False)\n",
        "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1Yv4NWgmDPV"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEiJXHIBmDPV",
        "outputId": "efee2682-0f38-425e-8e80-910a2d465dfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.10, 0.06\n",
            "0.10, 0.04\n",
            "0.27, 0.06\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor(0.05, grad_fn=<NllLossBackward0>), tensor(0.98))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBvD2c-lmDPV"
      },
      "source": [
        "PyTorch can auto-generate the BatchSampler for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4Zr5WCXmDPV"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIabKTSImDPV"
      },
      "source": [
        "PyTorch can also generate the Sequential/RandomSamplers too:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKHLJPawmDPW"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2)\n",
        "valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92BMxjaTmDPW",
        "outputId": "3d391a72-3b2d-469d-e975-d4e4d09efc88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
            "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.21, 0.14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
            "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.15, 0.16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
            "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05, 0.10\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor(0.01, grad_fn=<NllLossBackward0>), tensor(1.))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRvP5npumDPW"
      },
      "source": [
        "Our dataset actually already knows how to sample a batch of indices all at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4RPB1tAmDPW",
        "outputId": "40bc7a3c-f0c5-4341-e5d3-aa708b7bf76c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([9, 1, 3]))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds[[4,6,7]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVyDLrvLmDPW"
      },
      "source": [
        "...that means that we can actually skip the batch_sampler and collate_fn entirely:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLV4iRhEmDPW"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
        "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYXZJUiZmDPW",
        "outputId": "d40d04e2-0dc9-49d0-8fc2-9c7e6eceff69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 50, 784]), torch.Size([1, 50]))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "xb.shape,yb.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHydNQkamDPW"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s99u0unmmDPW"
      },
      "source": [
        "You **always** should also have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/), in order to identify if you are overfitting.\n",
        "\n",
        "We will calculate and print the validation loss at the end of each epoch.\n",
        "\n",
        "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jNaFJ3YmDPW"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb,yb in train_dl:\n",
        "            loss = loss_func(model(xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            tot_loss,tot_acc,count = 0.,0.,0\n",
        "            for xb,yb in valid_dl:\n",
        "                pred = model(xb)\n",
        "                n = len(xb)\n",
        "                count += n\n",
        "                tot_loss += loss_func(pred,yb).item()*n\n",
        "                tot_acc  += accuracy (pred,yb).item()*n\n",
        "        print(epoch, tot_loss/count, tot_acc/count)\n",
        "    return tot_loss/count, tot_acc/count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM2JQlAOmDPW"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9rN0YwqmDPW"
      },
      "source": [
        "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF439G4GmDPW"
      },
      "outputs": [],
      "source": [
        "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
        "model,opt = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOtXihMOmDPW",
        "outputId": "0a4af456-eec7-4917-90ba-c9627ff1998d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.0951265140157193 0.9733000087738037\n",
            "1 0.09963013818487525 0.9722000092267991\n",
            "2 0.1106003435049206 0.969400007724762\n",
            "3 0.09982822934631258 0.9742000102996826\n",
            "4 0.12104855466226581 0.9687000066041946\n",
            "CPU times: user 1.38 s, sys: 487 ms, total: 1.87 s\n",
            "Wall time: 1.54 s\n"
          ]
        }
      ],
      "source": [
        "%time loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGLPoWlfmDPW"
      },
      "source": [
        "## Export -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0RF3BHomDPW"
      },
      "outputs": [],
      "source": [
        "import nbdev; nbdev.nbdev_export()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuERXSMzmDPW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}